Prigozhin’s Propaganda Team: The St Petersburg Internet Research Agency (2013–2021) 

Europe-Asia Studies , 2026 , Ahead-of-print , 1 - 22 
https://doi.org/10.1080/09668136.2025.2588334 

Prigozhin’s Propaganda Team: The St Petersburg Internet Research Agency (2013–2021) 
Serge Poliakoff https://orcid.org/0000-0002-8875-9008 and Florian Toepfl https://orcid.org/0000-0001-5773-779X 

Abstract 
Existing research on the now defunct St Petersburg Internet Research Agency ( Agentstvo internet-issledovanii —IRA), owned by now-deceased oligarch Yevgeny Prigozhin, has focused on content analysis. Little is known about its organisation. This study uses 350 CVs of former IRA employees to provide insights into its structure and evolution (2013–2021). It shows that the IRA recruited mainly young, inexperienced individuals from St Petersburg universities, with a spike in recruitment when Russia annexed Crimea in 2014. This study details the IRA’s hierarchical structure and integration into the Russian media labour market, providing a framework for understanding similar disinformation organisations worldwide for the benefit of policymakers and researchers. Prigozhin’s digital influence empire, which included the IRA and his media company, Patriot Media Group, was dissolved following the mutiny led by Prigozhin’s Wagner Group in June 2023. 

© 2026 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group 

This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives License ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited, and is not altered, transformed, or built upon in any way. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent. 
A cross the W estern world, the network of R ussian legal entities known as the Internet Research Agency ( Agentstvo internet-issledovanii —IRA) gained widespread notoriety during its decade of operation. The initial discovery of the IRA by Russian and Western journalists in September 2013 and June 2015, respectively, led to the coining of the term ‘troll farm’ (Chen 2015 ) or ‘troll factory’ (Garmazhapova 2013 ) to describe institutionalised groups of digital workers whose objective is to influence the political discourse and decision-making dynamics of a particular society (Burgess et al . 2018 ). The IRA was controlled by Yevgeny Prigozhin, who maintained a close relationship with Russia’s autocrat Vladimir Putin (Walker & Sauer 2023 ). Prigozhin also founded the mercenary Wagner Group (Marten 2019 ). He was killed in a plane crash on 23 August 2023, exactly two months after his mutiny against the Kremlin and subsequent fall from Putin’s grace. The IRA and its activities have been scrutinised in an entire strand of academic literature 1 and through extensive investigative reporting (Garmazhapova 2013 ; Soshnikov 2013 ; Chen 2015 ). The IRA’s coordinated information operation targeting the 2016 US presidential elections was one of the ‘most studied of the social media age’ (Ehrett et al . 2021 , p. 1595). Extant research, however, has almost exclusively drawn upon analysis of content posted by inauthentic IRA accounts as identified by the leading social media platforms Facebook, Twitter and YouTube. 2 We have virtually no systematically collected academic knowledge on how the IRA functioned as an organisation, about its workforce, their tasks and the development of this highly secretive organisation over time. What we presently know about the IRA as an organisation is largely based on investigative reporting that draws on the testimonials of a very small number of whistleblowers, recorded at specific points in time. 3 
Our study seeks to fill this gap in academic knowledge by tapping entirely novel data. In spring 2022, we downloaded 350 curricula vitae (CVs), which former staff members of the IRA had self-published on Russia’s two primary job search platforms: HeadHunter (hh.ru) and SuperJob (superjob.ru). In these web profiles, individuals described their IRA employment to appeal to future employers. Using an open source intelligence (OSINT) approach (Hassan & Hijazi 2018 ), which has already been used to define Prigozhin as one of Russia’s ‘entrepreneurs of influence’ (Laruelle & Limonier 2021 , p. 318) and to study Russian hybrid aggression in Donbas (Hauter 2023 ), we were able to investigate Russian companies without field access, in a war-waging, increasingly repressive authoritarian country. 
Based on quantitative and qualitative analysis of these CVs, this study creates systematic knowledge, covering almost one decade of the IRA’s existence (2013–2021), about the demographics and qualifications of the IRA’s workforce, the work practices of these individuals, how the IRA was organised, and how it was perceived as an employer by other Russian (media) companies. Our data demonstrate that in the period 2013–2021, the IRA mainly employed people in their early twenties, with no or little work experience, and with degrees from St Petersburg universities. A spike in recruitment activity coincided with Russia’s annexation of Crimea in March 2014. A qualitative analysis of the CV dataset also provides detailed insights into the internal organisation of the IRA, revealing a broad five-level hierarchy. 
This study is the first detailed attempt to examine the organisational structure of a ‘troll factory’ and how it developed over almost a decade of operation. It advances the understanding of similar ‘disinformation-for-hire’ (Grohmann & Ong 2024 , p. 1) organisations. In particular, it contributes to the findings of Ayeb and Bonini ( 2024 ), who locate such organisations in the media industry market, as our examination of the subsequent career paths of former IRA staff shows that the IRA—despite functioning as a covert disinformation organisation—was integrated into the Russian labour market for media and communication professionals, with a significant proportion of former staff moving seamlessly into positions in sales and marketing, social media marketing and journalism. 
The IRA is arguably the best-known ‘troll farm’ to date and has received a lot of media attention. While many of the empirical findings of this study are descriptive and concern only one ‘disinformation-for-hire’ organisation (Grohmann & Ong 2024 , p. 1), they fill important gaps in academic knowledge about such entities. The solid descriptive knowledge provided here can serve as a basis for future research on the specific organisational processes and characteristics of the IRA and comparable entities across the world. 
The remainder of the article is organised as follows. In the next section, we review the existing research on how disinformation-for-hire is organised globally. The following section reviews the IRA with a specific focus on how it functioned as an organisation. Addressing key gaps in this literature, a subsequent section develops four specific research questions, referring also to gaps in knowledge left by extant investigative journalism. After a section on methods, we present our findings and the conclusion discusses how this study contributes to our understanding of the IRA and the organisational strategies of the global disinformation industry. 
The disinformation industry: the challenges of studying covert organisations 
Since the discovery of the IRA in 2013, the world has witnessed the emergence and growth of a new segment of the media market: the disinformation production industry, which has undergone a process of professionalisation and diversification (Grohmann & Ong 2024 ). This industry consists of institutionalised collectivities of digital labour whose aim is to influence the dynamics of political discourse and decision-making in a given society (Burgess et al . 2018 ). Some of these actors seek to exert influence in multiple societies, intending to affect the policies of foreign countries. Organisations in this industry have been called ‘troll factories’ (Linvill & Warren 2020 , p. 447), ‘troll farms’ (Freelon et al . 2022 , p. 561), ‘fake news factories’ (Bergmann 2018 , p. 152), ‘digital mercenaries’ (DiResta et al . 2022 , p. 222) and ‘digital black ops’ (Ong & Cabañes 2019 , p. 5771). These kinds of organisations have been detected in China (Han 2015 ), the Philippines (Ong & Cabañes 2019 ), Turkey (Bulut & Yörük 2017 ), Brazil (Ozawa et al . 2023 ) and South Korea (Keller et al . 2020 ). 
Academic inquiry into this industry faces considerable methodological and theoretical challenges. The covert nature of these organisations makes it difficult for researchers to gather information about them. Much of the published academic literature on disinformation organisations relies on the datasets of content attributed to these organisations published by the major Western social media companies (Facebook, Twitter) (Bastos & Farkas 2019 ; Linvill et al . 2021 ; DiResta et al . 2022 ). The practice of publishing these datasets also began with the release of IRA data in 2018 by Meta. From then on, social media companies regularly published data identified as ‘coordinated inauthentic behaviour’, 4 mostly content from foreign disinformation organisations attempting to interfere in other countries’ elections. 
Observing that disinformation production is part of the global media production market, Ong and Cabañes ( 2019 ) were the first to apply methods previously used to study traditional media organisations to disinformation production. In their study, they used interviews combined with participant observation to study disinformation producers in the Philippines. Following these steps, Ayeb and Bonini ( 2024 ) conducted interviews with eight disinformation workers in the Arab world. These interviews provided an insight into the work routines and feelings of those working in the disinformation organisations. 
Nevertheless, the covert nature of these organisations left the following challenges for future studies. First, as most of these organisations are located in countries that do not qualify as fully consolidated liberal democracies, sometimes in autocratic contexts, it is difficult for researchers to reach their employees. Thus, studies are based on a small number of interviews. Second, some aspects of the structure and operation of such organisations may be unknown to the interviewees; for example, respondents in the Ayeb and Bonini ( 2024 ) study did not know who owned the companies they worked for. Third, as some of these organisations work on a project basis, it is difficult to show how such an organisation might have changed in the course of its existence. 
To expand knowledge about the efforts of such organisations, in this article we propose to study the IRA, a disinformation organisation that existed for at least a decade, using a novel method of collecting relatively large datasets on the organisation itself rather than the content it produced. 
Prior research on the IRA: a focus on content 
In the wake of its information operation targeting the 2016 US presidential election, the IRA has been widely scrutinised academically. 5 This concerted effort has produced, among other things, detailed knowledge about the argumentative tactics employed by IRA accounts (Linvill et al . 2019 ; Rains et al . 2021 ), how IRA accounts appeared as vox populi in US news (Lukito et al . 2020 ), how the IRA promoted pseudoscientific content (Strudwicke & Grant 2020 ), how these social media accounts covered Russia’s hybrid warfare in Donbas in 2014 (Doroshenko & Lukito 2021 ) as well as their propagation of racist (Freelon et al . 2022 ) and anti-feminist attitudes (Bradshaw & Henle 2021 ). Scholars have also proposed a typology of inauthentic IRA profiles, distinguishing between ‘right troll, left troll, news feed, hashtag gamer, and fearmonger’ accounts (Linvill & Warren 2020 , p. 447). 6 In addition to examining the content posted by IRA accounts, researchers have drawn on a second source of data: social media ads purchased by the IRA. These datasets of ads linked to the IRA have been identified and made available to researchers by the data analytics teams of leading social media platforms, including Twitter and Facebook. For example, using one of these ad datasets, Al-Rawi and Rahman ( 2020 ) examined how the IRA microtargeted audiences in the US according to their race, sex, and political and religious beliefs. As this brief review shows, academic research on the IRA in recent years has two common features that can be applied to the global literature on disinformation-producing organisations. First, the majority of studies are based on the analysis of the content published by inauthentic accounts operated by the IRA. 7 Second, in terms of identifying troll accounts, academic research has almost exclusively relied on datasets provided by social media platforms. 8 
Identifying research gaps: lack of knowledge about the IRA as an organisation 
In contrast, what we presently know about the IRA’s staff, its organisational structures and its historical development is largely based on think tank reports, government documents, and journalistic articles. 9 To the best of our knowledge, no academic study has set out to create systematic knowledge about how the IRA functioned as an organisation, for instance, by conducting interviews with former IRA employees. The lack of this type of research is most likely due to a wealth of practical and ethical concerns, including potential negative repercussions for both the interviewees and the researchers, political self-censorship by academics both in Russia and abroad who potentially face threats from Russia’s repressive regime, and the scarcity of language skills and cultural knowledge about Russia in the global community of communication researchers. As we have already noted, the same problem is faced by researchers of other disinformation production organisations around the world, which results in a limited ability to capture the inner workings of these organisations using traditional methods. As a result, there is a dearth of systematically generated knowledge about the disinformation workforce and, in particular, about IRA operatives, their roles, and the functioning and development of the organisation. 
In this context, from a methodological point of view, this study is the first to investigate a communication organisation by analysing professional profiles posted by former employees on job search platforms. This OSINT approach originated in the field of intelligence studies, where it is defined as a set of methods and tools that facilitate ‘the collection of intelligence by exploiting publicly available resources’ (Hassan & Hijazi 2018 , p. 1). Using this approach, our study examines interactions in the job market and provides insights into trends in the disinformation-for-hire market. 
Research questions 
As we have noted before, the IRA is the quintessential disinformation-for-hire collective, giving the industry at least two of the names for its typical units (‘troll factory’ and ‘troll farm’). The existing gaps in our knowledge of the IRA also apply to the larger gaps about the inner workings of the other disinformation-for-hire collectives around the world. The IRA has been known to the public since 2013, so this section details the existing knowledge about the IRA in four areas, describes its contradictions and weaknesses, and then specifies four research questions that target these areas. 
RQ1: Socio-demographics and qualifications of IRA staff 
The first of the areas for which only rudimentary, and even partly contradictory, knowledge is available concerns the socio-demographics of the IRA’s workforce. Information about gender diversity, for instance, is inconclusive with one source (Patrikarakos 2017 ) claiming that IRA staff was mostly female. In a similar vein, details such as their age, citizenship, educational background, linguistic abilities, previous work experience and subsequent career paths remain largely unknown. To fill in this first set of gaps, we formulate the following two questions. First, what were the socio-demographics of the staff hired by the IRA, including age, gender, citizenship, education and language skills? Second, how long did staff work for the IRA and what were their prior and subsequent places of employment? 
RQ2: Development of the IRA as an organisation over time 
We have limited information from journalistic reports on the creation of the IRA and the evolution of its workforce. The US Department of Justice ( 2018 ) legally identifies the IRA as a network of seven camouflage companies based in St Petersburg: the Internet Research LLC; MediaSintez LLC; GlavSet LLC; MixInfo LLC; Azimut LLC; NovInfo LLC; and the Internet Research Agency LLC from which journalists/the US Department of Justice ( 2018 ) derived the network’s name. However, official registration periods of these camouflage companies do not always match the observations of investigative journalists on the operations of the IRA network (Rusyayeva & Zakharov 2017 ). 
From journalistic reports, we have sketchy knowledge of how the IRA was created and how its workforce developed over time. In 2018, a former associate of Prigozhin, Andrey Mikhaylov, stated that the IRA had 200 employees in 2013 (Korotkov 2018 ). In late 2014, a whistleblower estimated that ‘about 400 people occupied four floors of an office building and worked 12-hour shifts’ (Davlashyan & Titova 2018 ). On 6 July 2015, investigative journalist Andrei Soshnikov counted 300 employees entering and leaving the office between 8am and 11am (Soshnikov 2015 ). As a result, we have little reliable information about when the IRA companies were active and how many people they employed. Therefore, we ask, how did the workforce of the IRA network develop over time? 
RQ3: Departments, job roles and hierarchies at the IRA 
In parallel to the formal division of the IRA into seven legal entities (see above), the Mueller indictment (US Department of Justice 2018 ) and journalistic sources feature various listings of IRA subunits. According to the US Department of Justice ( 2018 , pp. 4–5), the IRA comprised: ‘a graphics department; a data analysis department; a search-engine optimisation (“SEO”) department; an information-technology (“IT”) department … and a finance department to budget and allocate funding’. That said, from these sources, it is not entirely clear, first, whether these and other subunits existed across the IRA network or within specific legal entities and, second, whether different terms were used to refer to the same subunits. Moreover, they use different labels to refer to the same sub-entities. For example, the most notorious sub-entity, allegedly tasked with interfering with the 2016 US election, is variously referred to as the ‘US/American department’ (Rusyayeva & Zakharov 2017 ) and the ‘Translator project’ (US Department of Justice 2018 , p. 6). In summary, we have limited knowledge of the departmental structure of the IRA, a far more sketchy understanding of the inner workings of the departments, whether they operated within or across legal entities, and what proportion of IRA staff were allocated to what tasks. Therefore, we ask, what subunits and job roles existed within which legal entities of the IRA network? 
A related area of knowledge concerns hierarchy levels at the IRA. Sorted by supposedly decreasing hierarchy level, extant sources identify the following roles: chief executive officer (CEO, director general), (deputy) heads/managers of projects/departments, team leads, editors-in-chief, bloggers, content managers, SEO specialists and illustrators. Journalists claimed that within the IRA ‘a classic scheme is used: a single head and line supervisors’ (Rusyayeva & Zakharov 2017 ). To advance knowledge in this area, we ask what can be learned from our data about the IRA’s hierarchical organisation. 
RQ4: Targeted platforms, tools and partners 
Our knowledge about what platforms the IRA targeted and its tools and partners is incomplete and anecdotal. In terms of targeted platforms, the Mueller indictment (US Department of Justice 2018 ) stated that the IRA operated on the following social media platforms: YouTube, Facebook, Instagram and Twitter. Liudmila Savchuk, one of the IRA’s whistleblowers, told journalists that the IRA also operated on the Russian platforms Livejournal and Odnoklassniki (Bidder 2015 ). To confirm and expand on this we interrogate our CV dataset and related previous anecdotal knowledge of the IRA’s target platforms, tools and partners, we examine what we can learn from the CV dataset about the platforms targeted, the technological tools used and the external partners involved by the IRA. 
Methods 
Sampling and data collection 
The goal of our sampling strategy was to collect professional web profiles (CVs) of individuals who had worked for the IRA. To do so, we searched for all known IRA-affiliated entities 10 on the two websites HeadHunter (hh.ru) and SuperJob (superjob.ru). In 2019, the shares in the Russian online recruiting market of these two platforms were estimated at 45% and 19%, respectively (Bryzgalova & Petlevoy 2019 ). Deploying these search terms in an exploratory stage in November 2021 and then in February and March 2022, we manually downloaded 393 web profiles. 
Each CV features a text box that allows owners to describe their tasks at the IRA in their own words. This text provides a wealth of unstructured knowledge about the tasks of the IRA, written by its staff. It offers a unique and diverse insight into their tasks, including targeted web platforms, IT tools and collaborations (answering RQ4). 
Potential biases owing to self-selection and social desirability 
Some elements of the quantitative data analysis (RQ1, RQ2 and RQ3) depend on the assumption that our sample of CVs is broadly representative of the population of CVs of individuals who worked for the IRA. As we see in the answer to RQ2, our sample is quite large in terms of numbers compared to the total IRA population documented by journalists. Other elements of the qualitative analysis (RQ2 and RQ4) rely on the assumption that the individuals who self-published the CVs reported on some aspects of their IRA work experience, at least overall, truthfully. 
Based on these assumptions, the first type of bias that our data may suffer from is self-selection bias, as all individuals self-selected their CVs into the sample by uploading their profiles to a job search platform. Our estimate of a specific characteristic of the IRA workforce (such as gender, age, university degree, see RQ1) will thus be distorted if individuals with some particular characteristics are less likely than other individuals to post their profiles on these recruitment websites or to include their IRA work experience on their CVs. We have no grounds to believe that our sample suffers from self-selection bias concerning most characteristics, including gender, age, university degree or duration of stay at the IRA. On the other hand, in terms of subsequent work experience, we cannot rule out the possibility that those who were less likely to list an IRA affiliation on their CVs were individuals who moved into the segment of the market where an association with the IRA entities indicted in the US could be detrimental (such as non-state-controlled media or Western companies). That said, a significant number of individuals in our dataset moved on to large Western retail brands, even after occupying leadership roles at the IRA. 
A second type of bias may result from the fact that the CVs were uploaded, or last updated, at different points in time. While approximately 55% ( n = 193 ) of CVs were updated within two years before we collected the data in March 2022, approximately 20.57% ( n = 72 ) of CVs were older than five years. 11 As CVs can only cover work experiences before the last update of the CV, we can plausibly assume that elements of the analysis tracing developments over time (RQ2) will slightly overestimate frequencies for earlier periods. 
The third type of bias that our dataset may suffer from is social desirability. As the profiles were published on a job-seeking website, it is plausible to assume that individuals describe their work experiences in a way that they believe makes them attractive to their future employers. That said, all individuals in the dataset considered their work experience at the IRA an asset to their professional profiles, as they did not omit their affiliation with the IRA from their CVs. As a close reading of the text boxes yields, individuals included in the dataset had no feelings of shame or guilt over their IRA activities, nor any fear of prosecution at home or abroad. 12 This perception is confirmed by the fact that many of the individuals, after their time at the IRA, found well-paid jobs in the non-political or government-affiliated segment of the labour market. At the same time, we assume that CVs might, by their nature, overstate qualifications, skills and achievements. In general, we assume that a sugar-coated version of all work experiences is narrated in the CVs, omitting weaknesses, failures and conflicts and exaggerating the contributions and skills of the author. 
Overall, we have high confidence in the findings as we present them in the following sections. For instance, we could identify no plausible reason to believe that the descriptive statistics reported in response to RQ1 are not broadly generalisable from the sample of CVs collected to the population of interest (that is, the IRA’s workforce). That said, if we have doubts concerning the accuracy or validity of specific claims, we reveal those and contextualise our claims at the specific points in the findings section where we present them (see, for instance, our response to RQ3). 
Data analysis and research ethics 
We wrote JavaScript code to automatically extract relevant information from the collected profiles. After manually removing or merging the information of 43 duplicate profiles, we obtained a JSON dataset of 350 unique CVs. After data collection and pre-processing, two Russian native speakers manually coded each non-IRA workplace into one of the predefined categories, based on the information provided in the CVs and additional information about the companies found on the web. An inter-coder reliability test showed a satisfactory level of agreement (Krippendorff’s α = 0 .947). We cleaned the data for the following variables: level of education, international experience, university city and field of study. Then we manually grouped the data provided in the CVs for two additional variables: type of job at IRA and type of job at other workplaces. 13 
In a subsequent qualitative step of the analysis, one of the authors of this study read all 350 profiles, with particular attention to the free text fields where CV authors provided details about their work experience. This qualitative coding effort was implemented with the help of the software MaxQDA and broadly followed a grounded theory logic, implementing the two steps of open and axial coding to generate categories inductively. In this qualitative coding effort, we were able to map all mentions of departments/projects, all mentions of the estimated size of these departments, and all hints as to hierarchical structures and tasks executed by specific positions. 14 
Data collection, processing and storage were implemented according to a rigorous ethics protocol that complied with European data protection law and was approved by the Institutional Review Board of the University of Passau. The research procedures developed aimed at guaranteeing, most importantly, that none of the individuals whose CVs are included in our dataset is identifiable by a leak of data from the authors’ research unit, by the dataset published or via published research articles. The ethics provisions stipulated that all data had to be pseudonymised immediately after collection and stored securely during the process of data analysis, and that only (translated) literal quotes from CVs that do not allow for identification of CV owners were published. 
Findings 
RQ1: Socio-demographics, career paths and language skills 
To identify the socio-demographic characteristics of IRA employees and to demonstrate their career paths, we present information on gender, time of employment, citizenship, age, education and career after the IRA in Table 1 . Overall, we see that the IRA recruited mainly people in their early twenties, with little or no work experience and with degrees from St Petersburg universities. Table 1 Socio-demographical Characteristics of CV Authors ( Table view ) 
Demographical characteristic Distribution Gender 
( n = 350) Male: 52% ( n = 181) 
Female: 48% ( n = 169) Time of employment 
( n = 350) 2 years and 4 months ( M = 2.3, SD = 1.9) Age (midterm through employment at the IRA) 
( n = 350) 26 years old ( M = 26.0, SD = 6.21) Citizenship 
( n = 316) Russia: 98.7% ( n = 312) 
Belarus: 0.6% ( n = 2) 
Kazakhstan: 0.3% ( n = 1) 
Turkmenistan: 0.3% ( n = 1) 
Ukraine: 0.3% ( n = 1) Education (before joining the IRA) 
( n = 299) University degree: 78.3% ( n = 234) 
University dropout: 7.7% ( n = 23) 
Vocational education (non-university): 9% ( n = 27) 
Military education: 1% ( n = 3) 
School only: 4% ( n = 12) University location 
( n = 234) St Petersburg: 78.3% ( n = 140) 
Moscow: 9.4% ( n = 22) 
Other Russian cities: 26.5% ( n = 62) 
Abroad: 4.3% ( n = 10) Field of study at university 
( n = 234) Economics and management: 22.2% ( n = 52) 
Journalism, PR and advertising: 19.2% ( n = 45) 
Foreign philology and languages: 7.7% ( n = 18) 
Law: 6.8% ( n = 16) 
Arts: 6.8% ( n = 16) 
Computer science: 6.4% ( n = 15) 
Tourism: 6% ( n = 14) 
Other fields of studies: 24.8% ( n = 58) Years between graduation and entry into the IRA 
( n = 251) Joined the IRA in year of graduation: 27.1% ( n = 53) 
1 year: 17.1% ( n = 43) 
2 years: 17.1% ( n = 43) 
3 years: 14.3% ( n = 36) 
4 years: 7.9% ( n = 36) 
5 years and more: 35.5% ( n = 89) Length of work experience before joining the IRA 
( n = 350) No work experience: 27.4% ( n = 96) 
Less than 1 year: 13.7% ( n = 48) 
Less than 2 years: 14.8% ( n = 52) 
More than 2 years: 44% ( n = 154) Career status at last CV update 
( n = 350) Moved to another employer: 57.1% ( n = 200) 
Still working at the IRA: 19.7% ( n = 69) 
Did not move to another employer but left the IRA: 23.1% ( n = 81) Employment distribution of job changers 
( n = 200) Sales and marketing: 17.5% ( n = 35) 
Social media marketing: 14.5% ( n = 29) 
Journalism: 10% ( n = 20) 
Gastronomy: 9% ( n = 18) 
Photo design: 6% ( n = 12) 
Management positions in other organisations: 6% ( n = 12) 
Other type of job: 21.1% ( n = 74) 

Note : M—median; SD—standard deviation. 
Concerning foreign language skills, the most widely mastered language in our sample was English, with 14.3% of workers (50 individuals) claiming advanced skills. A total of 47.1% of workers (165 people) claimed intermediate skills. In addition, an at least intermediate level was reported by 2.27% ( n = 9 ) for Ukrainian, 1.43% ( n = 5 ) for German, 1.15% ( n = 4 ) for Finnish and 0.86% ( n = 3 ) for French. In the text fields of the CVs, only 2.8% ( n = 10 ) of individuals explicitly claimed they used English for work. 15 As these data clearly show, only a very small group of IRA staff were able to work on non-English foreign-language information operations. 
RQ2: Development of the IRA network over time 
To trace the development of the IRA network over time, we calculated the number of individuals who claimed to work for each legal entity each month (see Figure 1 ). As our data indicate, the IRA network was created in a massive recruiting effort between approximately June 2013 and October 2014. A particularly steep increase in staff can be identified between early and mid-2014, coinciding broadly with Russia’s annexation of Crimea. In the first quarter of 2014 alone, 51 individuals (14.6% of IRA staff in our dataset) were hired (see Figure 1). The size of the agency then decreased only slightly until the summer of 2016, when it shrank massively by approximately half its employees. The data thus clearly document a pronounced decrease in IRA staff in the months before the US presidential elections of 8 November 2016. Twenty-seven former staff (approximately 7.7% of all individuals included in our dataset) left the IRA in August 2016 alone (see Figure 1). As these findings indicate, the IRA was not an organisation that was primarily set up, or specifically harnessed and funded, with an eye to the 2016 US presidential elections (see also data on language skills). Moreover, as the CV data demonstrate, there were several camouflage companies, which seemed to exist to a certain degree independently of being officially registered. As the CV data show, many camouflage companies employed IRA workers even years after their formal closure between 2017 and 2019, potentially paying their staff in cash. 16 The operation of several companies that comprised the IRA (according to the US indictment) continued until early 2022, the endpoint of our data collection. Thirty-two CVs claimed that their authors moved on to Prigozhin’s Patriot Media Group (PMG), often with identical positions and job descriptions, after leaving the IRA. 
Figure 1 . H eadcount of the IRA N etwork as A ccounted for in the CV D ataset, 2013–2021 

Note : Please note that we ceased reporting data in March 2021, as the final year’s figures were skewed due to many purportedly leaving the IRA just before posting their CVs online. 
RQ3: Departments and job roles at the IRA network 
In their web profiles, individuals described their position at the IRA (job roles) and their tasks in free text boxes. In these fields, individuals frequently mentioned a subunit they were affiliated with, referred to variously as ‘departments’, ‘projects’ or ‘directions’. Typical examples of such subunits were ‘the information department’, ‘the editorial department’, ‘the LiveJournal project’, the ‘exclusives and special investigations department’ and the ‘Middle East Direction’. 17 As both quantitative analysis and in-depth reading of the CV data suggest, the IRA network was thus composed of a combination of first ‘static’ subunits that existed throughout the analysis, such as the ‘information’ department. In parallel, the IRA featured a multitude of variously labelled, highly informal subunits that existed for limited periods and were typically organised around specific projects such as communication campaigns targeting specific platforms or events. At a more abstract level, the job roles and subunits mentioned were working towards performing broadly six tasks, described below. 
Mimicking ordinary citizens 
The first type of task was aimed at mimicking ordinary citizens’ voices, that is, producing seemingly ‘user-generated’ content. It was described as ‘maintaining social media accounts’ (M, 20, content manager) and ‘creating engagement in comments’ (M, 24, content manager). CVs in this category most frequently claimed affiliation with an ‘information department’ (29 mentions). Other CVs referred to a ‘copywriting department’ (2), a ‘blogosphere (blogging) department’ (2), an ‘information law department’ (1), an ‘information-analytical department’ (1), a ‘content department’ (1), a blogosphere department (1), and a ‘department of blogging and copywriting’ (1). The job role most often provided in the CVs for these positions was that of a ‘content manager’ ( n = 194 , 55.27% of all CVs). 
Mimicking journalism 
A second type of job role and subunit was primarily dedicated to mimicking journalistic content by producing (inauthentic) IRA news websites or social media news accounts. It was referred to as ‘positive coverage of the government’ (F, 32, journalist), ‘filling company websites and social media accounts’ (M, 25, editor) and ‘translating foreign articles’ (F, 25, editor). These job roles were typically described as ‘journalist’ or ‘editor’ (16.8%, n = 59 ) or ‘proofreader’ (3.13%, n = 11 ). Subunits frequently mentioned by these CV holders were ‘editorial department’, ‘media holding’ (not specified further) or RIA FAN, the name of a news organisation that was part of Prigozhin’s PMG. 
Advertising and marketing 
A third type of job role was dedicated to implementing advertising and marketing campaigns, which we understand as including the tasks of social media marketing (SMM) and search engine optimisation (SEO). Tasks and achievements cited in the CVs included ‘increasing monthly social traffic by up to 40%’ (F, 19, SEO specialist), ‘developing and implementing algorithms to promote content on social media platforms abroad’ (F, 23, SMM specialist) and even ‘propaganda, political PR’ (M, 44, SMM specialist). The most frequently mentioned job roles in this category were that of ‘marketing specialists’ (2.28%, n = 8 ), ‘SEO specialists’ (1.99%, n = 7 ) and ‘social media marketing SMM specialists’ (5.7%, n = 20 ). Affiliations included ‘SEO department’ (3), ‘(internet) marketing department’ (3), ‘department of contextual advertising’ (1), ‘marketing department’ (1), and ‘department set up to create and promote an online shop’ (1). 
Media monitoring and analysis 
A fourth type of subunit was tasked with media monitoring and analysis. Tasks were defined as ‘analysing the present political situation in the United States’ (F, 23, analyst), ‘formulating an all-inclusive media strategy’ (M, 24, lead analyst) and ‘reviewing employee key performance indicators, employee morale’ (M, 27, analyst). The most frequent job role in this category of CV was that of ‘analyst’ (3.42%, n = 12 ). Analysts claimed to be affiliated with an ‘analytical department’ (1), a ‘department of analytics’ (1), a ‘department of analytics and monitoring’ (1), and a ‘department of social media and media monitoring’ (1). 
Visual propaganda 
Fifth, the IRA employed staff specialising in video and image production. This work was described as ‘creating viral cartoons’ (M, 26, designer), ‘comics creation on political topics’ (M, 31, designer) and ‘artistic design of gift products for dignitaries of various states’ (M, 31, designer). Job roles included ‘designers’ and ‘video producers’ (5.7%, n = 20 ). These individuals claimed to be affiliated with a ‘video department’ (1), a ‘video production department’ (1), a ‘creative department’ (2), or a ‘designers department’ (1). 
Administrative and technical support 
The complexity of the IRA’s organisation is illustrated by the fact that it operated a whole range of subunits dedicated to specific administrative and technical tasks. These tasks included information technology (IT) support provided by ‘IT specialists’ ( n = 12 mentions) working for an ‘IT department’ (2 mentions), server administration provided by a ‘server administration department’ (2), cleaning provided by personnel (2) in a ‘cleaning department’ (2), ‘human resources specialists’ (4) in a ‘human resources department’ (1), office managers (4), accountants (3) in an accounting department, a legal department (1), and security personnel (2). The security staff, for example, was responsible (according to the descriptions in the CVs) for carrying out internal investigations, organising access controls to the company’s offices and issuing security passes. 
Hierarchical organisation 
A close reading of the CVs revealed broadly five levels of hierarchy which were widely applicable across the subunits of types 1–5 mentioned above (see Figure 2 ). Figure 2 . H ierarchical O rganisation of the IRA 
Entry-level positions were typically referred to as ‘specialists’ or ‘category 2 specialists’. Individuals affiliated with the information department, for instance, implemented the simplest ‘trolling’ tasks such as posting comments on news websites or social media (8.83% of all CVs, n = 31 ). In 25 (7.12%) CVs, these individuals had been promoted to the next level (7.12% of all CVs, n = 25 ), comprising job roles referred to as ‘content manager’, ‘category 1 specialist, information department’, ‘ copywriter’, ‘blogger’ or ‘journalist’. These second-level positions involved more sophisticated content production, administrative tasks (writing daily reports, curating photo archives) and, often, the management of teams of entry-level ‘specialists’ (62.5%, n = 219 ). At the third level of the hierarchy, we identified team leaders who were referred to as ‘editors’ in the departments producing journalistic content (7.69%, n = 27 ) and as ‘lead specialists’ in other departments (5.41%, n = 19 ). As can be seen from the CVs, these individuals were still involved in operational tasks in their sub-units but devoted most of their time to management and administrative tasks. At the fourth level of the hierarchy were deputy heads of department (1.71%, n = 6 ) and editors-in-chief (3.99%, n = 14 ). The latter managed entire projects and communicated with top management. At the fifth level, our CVs included two CVs of chief executive officers (0.57%, n = 2 ), each of whom supervised several departments. 
RQ4: Targeted platforms, tools and partners 
Platforms targeted 
A close reading of the text entered by the 350 individuals into the job description fields provides a comprehensive overview of the platforms on which the IRA was active. These included not only Twitter, Facebook and Instagram but also Telegram and YouTube. In addition, according to the CV data, the IRA operated on TikTok and Tumblr as well as across all major Russia-based platforms, including the social media platforms LiveJournal, VK (Vkontakte, a Russia-based social media platform broadly comparable to Facebook), OK ( Odnoklassniki , another Russia-based social media platform), Yandex.News (the news aggregator of the Russia-based search engine Yandex), the news recommendation platform Yandex.Zen, Kinopoisk (a Russia-based movie and review database broadly comparable to IMDB) and Pikabu. 
As explicitly mentioned in a number of the CVs, the IRA curated two entertainment-focused VK groups that published political information, which were still active as of September 2025 and each had more than 700,000 VK followers: AKULA (The Shark) (two mentions) and Derzkii kvadrat (Bold Square) (one mention). Both are also mentioned as being run by the IRA in the journalistic analysis of the leak of the data from the IRA’s IT department. 18 The CVs also pointed to several popular YouTube channels operated by the IRA, which had not been removed from the platform by the company (deplatformed) at the time of writing (November 2025): Znakom ’ tes’ Bob (Meet Bob; 1.96 million subscribers, three mentions), Chto, esli (What If; 463,000 subscribers, three mentions), Kratkaya istoriya (Brief history; 833,000 subscribers, three mentions) and CheBe (BW; 93,400 subscribers, one mention, also mentioned in the IT department data leak). 19 Chto, esli and Kratkaya istoriya started producing new content in 2025. A full list of social media profiles mentioned in the CV dataset is provided in the supplementary file. 
One CV (M, 24, sales manager) referred to a website called yourdigitalface.com, 20 which was part of the IRA’s US influence campaign, as a ‘company website’. According to journalistic reports, the IRA used this website to recruit US business owners as clients, using their businesses to make their fake accounts look legitimate (Holliday & Barry 2018 ). 
Technological tools used 
The 350 CVs analysed in this study provide a comprehensive overview of the technological tools used by the IRA. Key advertisement tools and services used in the departments of advertising include Google AdWords, Google Analytics, Google Tag Manager, Yandex.Direct and Yandex.Metrics. The use of these tools indicates that the IRA ran sophisticated advertising campaigns and collected analytical and marketing data. IRA staff also used CPA (cost per action) advertising through tools such as Advertise, ActionPay, Everad and Admitad, and teaser networks (clickbait advertising networks) such as DirectAdvert, MarketGid and AdHub. As the CV data show, the IRA ran long-term ad campaigns in social media, created email subscription lists, worked with RTB (real-time bidding) systems, and even conducted focus groups. 
In addition, the IRA used several in-house tools and technologies that made the simulation of user-generated content more efficient, including a synonymiser (a rewording tool) in the Russian language which resulted in a text difference of 25–35% (M, 33, programmer), a Telegram Bot which aggregated messages from various Telegram channels and sent them to a general channel with appropriate tags and categories, and a VK bot-service that was mentioned without explanation. 
Collaboration with Prigozhin or Kremlin-affiliated organisations 
Finally, the CV data also indicate that the IRA closely operated with a series of media partners either affiliated with Prigozhin, the owner of IRA, or the Russian state. One CV (M, 29, CEO) mentioned receiving ‘a certificate of appreciation from the President of the Russian Federation for assistance in the preparation and conduct of election campaign events’ and ‘interaction with state supervisory authorities’ during his employment with the IRA. The IRA’s media partners included the Russian news websites Cont.ws and Politikus.info, and Prigozhin-affiliated websites such as Politpuzzle.ru, RIA FAN and Nevskie novosti; the latter two were part of Prigozhin’s PMG (Rusyayeva & Zakharov 2017 ). Collaborations with Russia’s state-owned media included buying content from the news agencies Ruptly and TASS, and partnership with online cinemas (2×2 and ivi.ru). Partnerships with foreign streaming networks (Roku, Zype, Opera TV) were also mentioned. 
Discussion 
This study has generated a wealth of nuanced knowledge advancing research about the IRA specifically. Three of the most significant contributions are the following. To begin, this study is the first to provide reliable, highly detailed knowledge of the socio-demographics of the IRA workforce. Second, while our data allow no conclusions about the absolute numbers of the IRA’s workforce, this study is the first to be able to trace the evolution of the size of the IRA over almost a decade. Finally, while most of the existing literature focuses on IRA campaigns targeting the US presidential election, this may be misleading. Indeed, our data suggest that the IRA was not created primarily to target the US presidential election. Most of its staff were working on the Russian-language internet, including targeting Russian-speaking users in Ukraine against the broader background of the Russo–Ukrainian war (Dawson & Innes 2019 ). 
This insight into the organisational characteristics of the IRA contributes to the global study of the information production industry. The importance of this understanding lies in the fact that when disinformation is industrialised, the actors of this industry are organised in the same way as other business units, hence, the organisation of the IRA is similar to that of a medium-sized media or PR company and includes, like any business, support staff such as office managers, cleaners, security and IT personnel. This allowed the IRA to carry out its long-term operations, while at the same time setting up small and ephemeral departments, which were untraceable in our CV data, to target foreign countries (such as US and Middle Eastern departments). To better understand the global disinformation-for-hire collectives, it is therefore also important to understand the infrastructure on which they rely. While this question is obvious in the case of state-owned units in China (Han 2015 ) and Russia (DiResta et al . 2022 ), it is more difficult to trace in the case of ‘outsourced’ units (DiResta et al . 2022 , p. 222). 
This study highlights how smoothly the IRA network was integrated into the Russian ecosystem of public relations firms and (primarily) state-sponsored media outlets. As the CV data illustrate, the IRA was a reputable employer in the Russian labour market, with former IRA staff moving easily to other companies in sales and marketing, social media marketing and journalism (see RQ1). This finding technically locates it in the Russian media industry market, reflecting the findings of Ayeb and Bonini ( 2024 ), who locate such organisations (in their case, in the Arab world) in the media industry market of their respective countries. As we have seen, some IRA staff moved into new jobs in a media holding company comprising officially registered news outlets. In practice, however, it continued to host ‘troll’ operations under the guise of conventional journalism (Poliakoff 2025a ). 
The IRA recruited mainly people in their early twenties, with little or no work experience, and with degrees from St Petersburg universities. The demographic availability of such a workforce could be one of the reasons for the growth of such an industry in recent years, especially in countries that do not qualify as fully consolidated liberal democracies. First, the location of such an organisation in a megacity makes it easier to hide and accessible to a large workforce. Secondly, if the media market is undersaturated it can attract fresh graduates looking for employment but who wish to stay in St Petersburg, even though the Russian media industry is concentrated in Moscow. Third, given the supply of underemployed graduates, who are often forced to take jobs that do not match their qualifications, such as working in fast food, retail or other service industries, there is a readily available pool of potential employees willing to accept lower wages and less stable employment conditions in order to do ‘creative’ work. 
According to a common definition (Fetzer 2004 ), the production of disinformation involves the deliberate dissemination of factually false claims. This study found that the operations of a disinformation production collective—in this case, the IRA—are not actually limited to disinformation per se . This corresponds to Harsin’s ( 2024 ) critique of disinformation-for-hire scholarship being too narrow, advocating that the scope encompass the ‘5Ps’: propaganda, PR, promotional culture, political consulting and post-truth. We see in our data that the IRA not only deliberately spread factually false claims but also sought to conceal its existence and its role in manufacturing and spreading those false claims from the public, which is not necessarily implied in standard definitions of disinformation. 
In line with Harsin’s ( 2024 ) proposal we see that the IRA’s overarching mission encompassed a wide range of propaganda efforts, which we understand to be ‘deliberate, systematic attempts to shape perceptions, manipulate cognitions, and direct behaviour to achieve a response that furthers the desired intent of the propagandist’ (Jowett & O’Donnell 2018 , p. 7). Interestingly, the IRA engaged exclusively in covert (also known as ‘black’) propaganda, a classic subtype of propaganda that has two characteristics: first, ‘the source [of the messages] is concealed or attributed to a false authority’ and, second, it disseminates not only factually accurate content but also ‘lies, fabrications and deceptions’ (Jowett & O’Donnell 2018 , p. 18). Similarly, as our analysis of SNS accounts and media outlets run by the IRA shows, none of these accounts contained any indication that they were run by the IRA. 
Moreover, there are obvious traces of another ‘P’ mentioned by Harsin ( 2024 ): we see that certain departments were doing direct PR and promotional work, setting up campaigns on global advertising platforms, which requires certain technical and professional skills not related to disinformation and propaganda. This contributes to a more complex understanding of the workers in the disinformation production industry: as we see in our dataset, the IRA not only employed ‘trolls’, who directed disinformation and propaganda work, but also professionals who helped them set up advertising campaigns, built the IT tools for content distribution, and navigated the world of political PR. As we see, the IRA has developed chatbots, which is consistent with reports that similar organisations in existence at the time of writing (October 2024) are employing AI specialists to perform these tasks (Darwish 2024 ). 
The covert nature of the IRA also leaves some questions not fully resolved. Previous research lacked a consensus on the IRA’s ownership. It has variously been referred to as a ‘private company’ (Bastos & Farkas 2019 , p. 3; DiResta et al . 2022 , p. 222), an entity ‘reportedly linked to the Russian government’ (Bastos & Farkas 2019 , p. 1), and as one ‘funded by the Russian government’ (Freelon et al . 2022 , p. 561). From the perspective of our CV data, the IRA appears as a genuinely private operation: we see no evidence of direct state control in its day-to-day activities, with employees circulating between different registered entities and moving into other media-related jobs under Prigozhin’s umbrella. Apart from the obvious connection of Prigozhin himself to Putin and the Russian government, the connection of the IRA to the state manifests itself in our data: peak recruitment coincided with Russia’s military campaigns over the last decade, the data also refer to campaigns that obviously benefitted Russian foreign and domestic policy and to the cooperation of the IRA with Russian state propaganda outlets. This distinguishes the IRA from disinformation production units in other authoritarian regimes, such as China, where numerous state agencies are often directly involved in sponsoring internet commentators, including local propaganda bureaus, ministries, and even schools and state-owned enterprises (Han 2015 ) and also from other covert similar units within Russia that are integrated into the state apparatus, such as the propaganda units of Russian intelligence services (DiResta et al . 2022 ). While we see that the IRA was never formally part of Russia’s official state structures, our data suggest that its activities were well-known to, and even honoured by, the state (as previously mentioned, the CEO of one the IRA companies received a certificate of appreciation from Putin). 
The nature of funding is harder to identify through our data. Even if the IRA appears at a structural level to have been similar to a medium-sized media or PR agency, anything that might hint at sources of income are absent from the CVs. There is no mention of sales departments nor of any financial achievements by its staff (although our CV dataset does contain some minor references to commercial partnerships). Despite that, our dataset shows that the IRA performed tasks of strategic importance to the Russian government. We find no evidence in the data and existing literature (US Department of Justice 2018 ; DiResta et al . 2022 ) that the IRA received direct payments or direct government contracts. The IRA’s financial resources were provided exclusively by the organisation’s principal, the Russian oligarch Prigozhin, who also ran a large catering company and the Wagner Group. Prigozhin’s entire fortune was made through his personal contact with Putin: his catering company won state tenders and the Wagner Group was financed by the state (Walker & Sauer 2023 ). There is no reason to believe that any of the IRA’s and Prigozhin’s actions before the start of Russia’s full-scale invasion of Ukraine in 2022 were carried out without the approval of his patron in the Kremlin. The IRA’s primary goal—in addition to Prigozhin’s own business and power interests—can be described as securing the goodwill of Putin and Russia’s ruling elites; for example, getting more direct funding for either Prigozhin’s catering business or the Wagner Group. Therefore, we agree with the understanding of the IRA as the Kremlin’s ‘outsourced trolls’ (DiResta et al . 2022 , p. 222) rather than directly ‘funded by the Russian government’ (Freelon et al . 2022 , p. 561). Moreover, we can assume that the IRA’s role was similar to that of another product of ‘outsourcing’ activities to the same ‘agent’ (Prigozhin), the Wagner Group, ‘a component of Putin’s current “information warfare” strategy, using obfuscation in their relationship with the state to sow confusion and chaos among Russia’s enemies’ (Marten 2019 , p. 187). 
Limitations and paths for future research 
Although self-published CVs provide detailed insights into the IRA’s structure, they offer a limited understanding of the feelings and perceptions of its workers. To improve future research, qualitative interviews, possibly with former IRA employees who left Russia after the 2022 full-scale invasion of Ukraine, could be beneficial. 
The findings of this study solely pertain to the core IRA legal entities that were identified in the 2018 indictment by the US Department of Justice. Already since November 2014, the IRA’s head, Prigozhin, redirected a substantial portion of his disinformation campaigns towards organisations under the new umbrella of the newly created Patriot Media Group (PMG). For comparative analysis, one of the authors of this study examined and reviewed the CVs of PMG staff in a similar way to the IRA (Poliakoff 2025a ). Both the IRA and the PMG ceased to exist in June 2023, shortly after the uprising of the Wagner Group which has been widely referred to as Prigozhin’s ‘mutiny’. Yevgeny Prigozhin was killed two months later, on 23 August, in a plane crash near Kuzhenkino, Russia. 
Although the empirical findings of this study are mainly descriptive, they could serve as a basis for further research into the global disinformation industry. As this study is the first to use this novel methodology, we urge researchers studying the global phenomena of disinformation-for-hire to implement it in other contexts. We believe that the combination of knowledge gained from studying the content produced by these organisations, the feelings and perceptions of their employees gathered through interviews, and the organisational structures provided in CVs can help us to better theorise this covert segment of the global media market. 
As we pointed out in the article, the issue of IRA ownership cannot be resolved by using CV data alone. There is a need for a detailed study explaining the nature of the ‘outsourcing’ of disinformation activities in the case of Prigozhin, which would also help to understand the reasons why he mutinied against the Kremlin in 2023 and why he failed. We plan to examine this issue in detail in a future project using additional sources of data, including interviews and document analysis. 
Notes 

1. 
For recent overviews of this literature, see, for example, DiResta et al . ( 2022 ), Ehrett et al . ( 2021 ). 

2. 
See, for example, Linvill et al . ( 2019 ), Golovchenko et al . ( 2020 ), Ehrett et al . ( 2021 ), Francois et al . ( 2021 ), Zhang et al . ( 2021 ). The term ‘inauthentic’, as used here, refers to fake content, created by real people, also known as ‘trolls’. 

3. 
See, for example, Garmazhapova ( 2013 ), Soshnikov ( 2013 ), Chen ( 2015 ). 

4. 
‘Meta's Ongoing Efforts Regarding Russia's Invasion of Ukraine’, Meta, 26 February 2022, available at: https://about.fb.com/news/2022/02/metas-ongoing-efforts-regarding-russias-invasion-of-ukraine , accessed 22 March 2024. 

5. 
For example, Ehrett et al . ( 2021 ), DiResta et al . ( 2022 ). 

6. 
See also Ehrett et al . ( 2021 ). 

7. 
See, for example, Ehrett et al . ( 2021 ), DiResta et al . ( 2022 ). 

8. 
See, for example, Strudwicke and Grant ( 2020 ), Freelon et al . ( 2022 ). 

9. 
See, for example, Patrikarakos ( 2017 ), Kurowska and Reshetnikov ( 2018 ), Rid ( 2020 ). 

10. 
These entities include: GlavSet’, Internet-issledovaniya, Teka, Azimut, MiksInfo, MediaSintez, Agentstvo internet issledovanii, NovInfo, N’yuinform, Inforekator, Polit·ekspert, Slovo i delo and PolitRossiya. For the full list, including spelling errors of CV owners, see Table 5 in the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

11. 
For detailed descriptive statistics of the ‘last updated’ variable, see Figure 1 of the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

12. 
This situation underwent a shift in the aftermath of Prigozhin's mutiny (see Poliakoff 2025b ). 

13. 
For details see parts 4–6 of the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

14. 
For a full list of all variables captured and categories created, please see Part 6 of the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

15. 
For more detailed data see Table 2 of the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

16. 
See Figure 2 of the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

17. 
For a full list of subunits mentioned, see Table 4 of the supplementary file, available at: https://doi.org/10.5281/zenodo.14197201 . 

18. 
‘Kibervoiska Prigozhina’, Dos’ye , 18 March 2023, available at: https://dossier.center/prig-it/ , accessed 10 October 2024. 

19. 
‘Kibervoiska Prigozhina’, Dos’ye , 18 March 2023, available at: https://dossier.center/prig-it/ , accessed 10 October 2024. 

20. 
Yourdigitalface.com, 2018, available at: http://web.archive.org/web/20180221004903/ http://yourdigitalface.com/ , accessed 2 November 2023. 
Acknowledgements 
Research for this article was conducted while Serge Poliakoff was working at the University of Passau, Germany. This article has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme [grant number 819025]. It is part of the ERC consolidator project on ‘The Consequences of the Internet for Russia’s Informational Influence Abroad’ ( www.rusinform.uni-passau.de/en ). The participants in this study did not give written consent for their data (which they had made publicly available) to be collected and analysed for the purposes of academic research. Therefore, owing to the sensitive nature of our analysis and following our ethics protocol, we have not published the full dataset. The requirement for written consent was waived by our ethics protocol, which complies with European data protection law and was approved by the University of Passau Institutional Review Board. According to this protocol, we can make a pseudonymised version of the dataset available to trusted researchers upon request (for instance, for replication purposes), after acquiring permission from the Institutional Review Board. A supplementary file providing further analyses and information about the dataset is available at the following link: https://doi.org/10.5281/zenodo.14197201 . 
Disclosure statement 
No potential conflict of interest was reported by the author(s). 
Notes on contributors 

S erge P oliakoff , University of Amsterdam, Postbus 94550, Amsterdam 1090 GN, The Netherlands. Email: s.poliakoff@uva.nl 

F lorian T oepfl , University of Passau, Dr.-Hans-Kapfinger-Str. 14c, Passau 94032, Germany. Email: Florian.Toepfl@uni-passau.de 
References 

Al-Rawi, A. & Rahman, A. (2020) ‘Manufacturing Rage: The Russian Internet Research Agency’s Political Astroturfing on Social Media’, First Monday , 25, 9. 

Ayeb, M. & Bonini, T. (2024) ‘“It Was Very Hard for Me to Keep Doing That Job”: Understanding Troll Farm’s Working in the Arab World’, Social Media + Society , 10, 1. Crossref . Web of Science . 

Bastos, M. & Farkas, J. (2019) ‘“Donald Trump Is My President!”: The Internet Research Agency Propaganda Machine’, Social Media + Society , 5, 3. Crossref . Web of Science . 

Bergmann, E. (2018) ‘Transmission and Fake News’, in Bergmann, E. (ed.) Conspiracy & Populism: The Politics of Misinformation (Cham, Springer International). Crossref . 

Bidder, B. (2015) ‘Interview with Ex Russian Internet Troll Lyudmila Savchuk’, Der Spiegel , 1 June, available at: https://www.spiegel.de/international/world/interview-with-ex-russian-internet-troll-lyudmila-savchuk-a-1036539.html , accessed 29 March 2023. 

Bradshaw, S. & Henle, A. (2021) ‘The Gender Dimensions of Foreign Influence Operations’, International Journal of Communication , 15. Web of Science . 

Bryzgalova, E. & Petlevoy, V. (2019) ‘HeadHunter vnov’ gotovitsya provesti IPO’, Vedomosti , 12 April, available at: https://www.vedomosti.ru/technology/articles/2019/04/11/798966-headhunter-ipo , accessed 27 March 2023. 

Bulut, E. & Yörük, E. (2017) ‘Digital Populism: Trolls and Political Polarization of Twitter in Turkey’, International Journal of Communication , 11. Web of Science . 

Burgess, J., Poell, T. & Marwick, A. E. (eds) (2018) The SAGE Handbook of Social Media (London, Sage). Crossref . 

Chen, A. (2015) ‘The Agency’, New York Times , 2 June, available at: https://www.nytimes.com/2015/06/07/magazine/the-agency.html , accessed 2 February 2022. 

Darwish, A. (2024) ‘Russia’s AI Interference in 2024 US Elections’, Bloomsbury Intelligence and Security Institute , available at: https://bisi.org.uk/reports/russias-ai-interference-in-2024-us-elections , accessed 8 October 2024. 

Davlashyan, N. & Titova, I. (2018) ‘Ex-workers at Russian “Troll Factory” Trust US Indictment’, Washington Post , 20 February, available at: https://www.washingtonpost.com/world/the_americas/ex-workers-at-russian-troll-factory-trust-us-indictment/2018/02/19/b0007e70-15de-11e8-930c-45838ad0d77a_story.html , accessed 19 December 2022. 

Dawson, A. & Innes, M. (2019) ‘The Internet Research Agency in Europe 2014–2016’, Cardiff University Crime and Security Research Institute, available at: https://www.cardiff.ac.uk/__data/assets/pdf_file/0007/2733325/The-Internet-Research-Agency-In-Europe-2014-2016.pdf , accessed 21 September 2025. 

DiResta, R., Grossman, S. & Siegel, A. (2022) ‘In-house vs. Outsourced Trolls: How Digital Mercenaries Shape State Influence Strategies’, Political Communication , 39, 2. Crossref . Web of Science . 

Doroshenko, L. & Lukito, J. (2021) ‘Trollfare: Russia’s Disinformation Campaign During Military Conflict in Ukraine’, International Journal of Communication , 15. Web of Science . 

Ehrett, C., Linvill, D. L., Smith, H., Warren, P. L., Bellamy, L., Moawad, M., Moran, O. & Moody, M. (2021) ‘Inauthentic Newsfeeds and Agenda Setting in a Coordinated Inauthentic Information Operation’, Social Science Computer Review , 40, 6. Web of Science . 

Fetzer, J. H. (2004) ‘Disinformation: The Use of False Information’, Minds and Machines , 14, 2. Crossref . Web of Science . 

Francois, C., Barash, V. & Kelly, J. (2021) ‘Measuring Coordinated versus Spontaneous Activity in Online Social Movements’, New Media & Society , 25, 11. Web of Science . 

Freelon, D., Bossetta, M., Wells, C., Lukito, J., Xia, Y. & Adams, K. (2022) ‘Black Trolls Matter: Racial and Ideological Asymmetries in Social Media Disinformation’, Social Science Computer Review , 40, 3. Crossref . Web of Science . 

Garmazhapova, A. (2013) ‘Gde zhivut trolli. I kto ikh kormit’, Novaya gazeta , 9 September, available at: https://novayagazeta.ru/articles/2013/09/07/56253-gde-zhivut-trolli-i-kto-ih-kormit/ , accessed 20 December 2022. 

Golovchenko, Y., Buntain, C., Eady, G., Brown, M. A. & Tucker, J. A. (2020) ‘Cross-platform State Propaganda: Russian Trolls on Twitter and YouTube During the 2016 US Presidential Election’, The International Journal of Press/Politics , 25, 3. Crossref . Web of Science . 

Grohmann, R. & Ong, J. C. (2024) ‘Disinformation-for-Hire as Everyday Digital Labor: Introduction to the Special Issue’, Social Media + Society , 10, 1. Crossref . Web of Science . 

Han, R. (2015) ‘Manufacturing Consent in Cyberspace: China’s “Fifty-cent Army”’, Journal of Current Chinese Affairs , 44, 2. Crossref . 

Harsin, J. (2024) ‘Three Critiques of Disinformation (For-Hire) Scholarship: Definitional Vortexes, Disciplinary Unneighborliness, and Cryptonormativity’, Social Media + Society , 10, 1. Crossref . Web of Science . 

Hassan, N. A. & Hijazi, R. (2018) Open Source Intelligence Methods and Tools: A Practical Guide to Online Intelligence (New York, NY, Apress). Crossref . 

Hauter, J. (2023) ‘Forensic Conflict Studies: Making Sense of War in the Social Media Age’, Media, War & Conflict , 16, 2. Crossref . Web of Science . 

Holliday, S. & Barry, R. (2018) ‘Russian Operation Targeted US Business Owners’, Wall Street Journal , 20 December, available at: https://www.wsj.com/articles/russian-operation-targeted-u-s-business-owners-11545339158 , accessed 2 November 2023. 

Jowett, G. S. & O’Donnell, V. (2018) Propaganda & Persuasion (Thousand Oaks, CA, Sage). 

Keller, F. B., Schoch, D., Stier, S. & Yang, J. (2020) ‘Political Astroturfing on Twitter: How to Coordinate a Disinformation Campaign’, Political Communication , 37, 2. Crossref . Web of Science . 

Korotkov, D. (2018) ‘Povar so svoimi tarakanami’, Novaya gazeta , 8 November, available at: https://novayagazeta.ru/articles/2018/11/08/78496-provokatsii-prigozhina/ , accessed 19 December 2022. 

Kurowska, X. & Reshetnikov, A. (2018) ‘Neutrollization: Industrialized Trolling as a Pro-Kremlin Strategy of Desecuritization’, Security Dialogue , 49, 5. Crossref . Web of Science . 

Laruelle, M. & Limonier, K. (2021) ‘Beyond “Hybrid Warfare”: A Digital Exploration of Russia’s Entrepreneurs of Influence’, Post-Soviet Affairs , 37, 4. Crossref . Web of Science . 

Linvill, D. L., Boatwright, B. C., Grant, W. J. & Warren, P. L. (2019) ‘“THE RUSSIANS ARE HACKING MY BRAIN!” Investigating Russia’s Internet Research Agency Twitter Tactics During the 2016 United States Presidential Campaign’, Computers in Human Behavior , 99. Crossref . Web of Science . 

Linvill, D. L. & Warren, P. L. (2020) ‘Troll Factories: Manufacturing Specialized Disinformation on Twitter’, Political Communication , 37, 4. Crossref . Web of Science . 

Linvill, D. L., Warren, P. L. & Moore, A. E. (2021) ‘Talking to Trolls—How Users Respond to a Coordinated Information Operation and Why They’re So Supportive’, Journal of Computer-Mediated Communication , 27, 1. Crossref . Web of Science . 

Lukito, J., Suk, J., Zhang, Y., Doroshenko, L., Kim, S. J., Su, M. H., Xia, Y., Freelon, D. & Wells, C. (2020) ‘The Wolves in Sheep’s Clothing: How Russia’s Internet Research Agency Tweets Appeared in US News as Vox Populi’, International Journal of Press/Politics , 25, 2. Crossref . Web of Science . 

Marten, K. (2019) ‘Russia’s Use of Semi-state Security Forces: The Case of the Wagner Group’, Post-Soviet Affairs , 35, 3. Crossref . Web of Science . 

Ong, J. & Cabañes, J. (2019) ‘When Disinformation Studies Meets Production Studies: Social Identities and Moral Justifications in the Political Trolling Industry’, International Journal of Communication , 13. Web of Science . 

Ozawa, J. V. S., Woolley, S. C., Straubhaar, J., Ried, M. J., Joseff, K. & Gursky, J. (2023) ‘How Disinformation on WhatsApp went from Campaign Weapon to Governmental Propaganda in Brazil’, Social Media + Society , 9, 1. Crossref . Web of Science . 

Patrikarakos, D. (2017) War in 140 Characters: How Social Media Is Reshaping Conflict in the Twenty-First Century (New York, NY, Basic Books). 

Poliakoff, S. (2025a) ‘Trolls Behind the Mask of Journalists: How Yevgeny Prigozhin’s Patriot Media Group was Organized’, Problems of Post-Communism , 72, 5. Crossref . Web of Science . 

Poliakoff, S. (2025b) ‘Nach dem Aufstand: der Untergang von Jewgenij Prigoschins digitalem Imperium’, Russland-Analysen , 464, available at: https://laender-analysen.de/russland-analysen/464/russlandanalysen464.pdf , accessed 10 December 2025. Crossref . 

Rains, S. A., Shmargad, Y., Coe, K., Kenski, K. & Bethard, S. (2021) ‘Assessing the Russian Troll Efforts to Sow Discord on Twitter During the 2016 US Election’, Human Communication Research , 47, 4. Crossref . Web of Science . 

Rid, T. (2020) Active Measures: The Secret History of Disinformation and Political Warfare (London, Profile Books). 

Rusyayeva, P. & Zakharov, A. (2017) ‘Rassledovanie RBK: kak “fabrika trollei” porabotala na vyborakh v SShA’, RBK , 17 October, available at: https://www.rbc.ru/technology_and_media/17/10/2017/59e0c17d9a79470e05a9e6c1 , accessed 16 January 2023. 

Soshnikov, A. (2013) ‘Pod Peterburgom obnaruzheno logovo trolley, kotorye kleymyat Naval’nogo i khvalyat russkoe kino’, MR7.ru , 4 September, available at: https://mr-7.ru/articles/90769/ , accessed 2 February 2022. 

Soshnikov, A. (2015) ‘Chelovek-pauk i neformaly na sluzhbe u “fabriki trollei”’, New Times , 21 July, available at: https://newtimes.ru/articles/detail/100461 , accessed 19 December 2022. 

Strudwicke, I. J. & Grant, W. J. (2020) ‘#JunkScience: Investigating Pseudoscience Disinformation in the Russian Internet Research Agency Tweets’, Public Understanding of Science , 29, 5. Crossref . Web of Science . 

US Department of Justice (2018) ‘Grand Jury Indicts Thirteen Russian Individuals and Three Russian Companies for Scheme to Interfere in the United States Political System’, 16 February, available at: https://www.justice.gov/opa/pr/grand-jury-indicts-thirteen-russian-individuals-and-three-russian-companies-scheme-interfere , accessed 20 November 2024. 

Walker, S. & Sauer, P. (2023) ‘Yevgeny Prigozhin: The Hotdog Seller who Rose to the Top of Putin’s War Machine’, The Guardian , 23 August, available at: https://www.theguardian.com/world/2023/jan/24/yevgeny-prigozhin-the-hotdog-seller-who-rose-to-the-top-of-putin-war-machine-wagner-group , accessed 30 August 2023. 

Zhang, Y., Lukito, J., Su, M.-H., Suk, J., Xia, Y., Kim, S. J., Doroshenko, L. & Wells, C. (2021) ‘Assembling the Networks and Audiences of Disinformation: How Successful Russian IRA Twitter Accounts Built their Followings, 2015–2017’, Journal of Communication , 71, 2. Crossref . Web of Science . 